{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AAL Australia: 4Q Sales Report**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data Wrangling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 Data Inspection**\n",
    "\n",
    "_It's the process of getting familiar with the data in order to identify quality and structure issues._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the DataFrame:\n",
      "         Date        Time State     Group  Unit  Sales\n",
      "0  1-Oct-2020     Morning    WA      Kids     8  20000\n",
      "1  1-Oct-2020     Morning    WA       Men     8  20000\n",
      "2  1-Oct-2020     Morning    WA     Women     4  10000\n",
      "3  1-Oct-2020     Morning    WA   Seniors    15  37500\n",
      "4  1-Oct-2020   Afternoon    WA      Kids     3   7500\n",
      "\n",
      "Last 5 rows of the DataFrame:\n",
      "             Date        Time State     Group  Unit  Sales\n",
      "7555  30-Dec-2020   Afternoon   TAS   Seniors    14  35000\n",
      "7556  30-Dec-2020     Evening   TAS      Kids    15  37500\n",
      "7557  30-Dec-2020     Evening   TAS       Men    15  37500\n",
      "7558  30-Dec-2020     Evening   TAS     Women    11  27500\n",
      "7559  30-Dec-2020     Evening   TAS   Seniors    13  32500\n",
      "\n",
      "DataFrame Summary\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7560 entries, 0 to 7559\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    7560 non-null   object\n",
      " 1   Time    7560 non-null   object\n",
      " 2   State   7560 non-null   object\n",
      " 3   Group   7560 non-null   object\n",
      " 4   Unit    7560 non-null   int64 \n",
      " 5   Sales   7560 non-null   int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 354.5+ KB\n",
      "None\n",
      "\n",
      "Does the DataFrame have any null value?: False\n",
      "\n",
      "Number of duplicates: 0\n",
      "\n",
      "List of numerical columns:\n",
      "Index(['Unit', 'Sales'], dtype='object')\n",
      "\n",
      "List of categorical columns:\n",
      "Index(['Date', 'Time', 'State', 'Group'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./Data/AAL_Q4-2020_Sales.csv\")\n",
    "\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(df.head(5))\n",
    "\n",
    "print(f\"\\nLast 5 rows of the DataFrame:\")\n",
    "print(df.tail(5))\n",
    "\n",
    "print(\"\\nDataFrame Summary\")\n",
    "print(df.info())\n",
    "\n",
    "has_null = df.isnull().values.any()\n",
    "print(\"\\nDoes the DataFrame have any null value?:\", has_null)\n",
    "\n",
    "number_of_duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicates: {number_of_duplicates}\")\n",
    "\n",
    "print(\"\\nList of numerical columns:\")\n",
    "numerical_columns = df.select_dtypes(include=[\"number\"]).columns\n",
    "print(numerical_columns)\n",
    "\n",
    "print(\"\\nList of categorical columns:\")\n",
    "categorical_columns = df.select_dtypes(exclude=[\"number\"]).columns\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Data Cleaning**\n",
    "\n",
    "_It's the process of handling missing data, removing duplicates, converting data types, trimming whitespace, correcting inconsistencies, standardizing formats, dealing with outliers, and validating accuracy._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time unique values: ['Morning' 'Afternoon' 'Evening']\n",
      "State unique values: ['WA' 'NT' 'SA' 'VIC' 'QLD' 'NSW' 'TAS']\n",
      "Group unique values: ['Kids' 'Men' 'Women' 'Seniors']\n"
     ]
    }
   ],
   "source": [
    "# Handling duplicates:\n",
    "if number_of_duplicates > 0:\n",
    "    df = df.drop_duplicates(keep=\"first\")\n",
    "\n",
    "# Handling missing data for numerical columns:\n",
    "for column in numerical_columns:\n",
    "    if df[column].isnull().any():\n",
    "        column_median = df[column].median()\n",
    "        df[column] = df[column].fillna(column_median)\n",
    "\n",
    "# Handling missing data for categorical columns:\n",
    "for column in categorical_columns:\n",
    "    if df[column].isnull().any():\n",
    "        df[column] = df[column].fillna(\"Unknown\")\n",
    "\n",
    "\n",
    "# Identify and correct misspelled words and unnecessary whitespace:\n",
    "for column in categorical_columns:\n",
    "    if column != \"Date\":\n",
    "        df[column] = df[column].str.strip()\n",
    "        unique_values = df[column].unique()\n",
    "        print(f\"{column} unique values: {unique_values}\")\n",
    "\n",
    "# Handling Outliers:\n",
    "SALES_COLUMN = \"Sales\"\n",
    "\n",
    "q1 = df[SALES_COLUMN].quantile(0.25)\n",
    "q3 = df[SALES_COLUMN].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Tagging all the 'sales outliers' with True or False\n",
    "condition = (df[SALES_COLUMN] >= lower_bound) & (df[SALES_COLUMN] <= upper_bound)\n",
    "df[\"Sales_Outlier\"] = ~condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3 Data Transformation**\n",
    "\n",
    "_It involves converting data from its original form into a format that is more suitable for analysis._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Transforming Date column to YYYY-MM-DD:\n",
    "DATE_COLUMN = \"Date\"\n",
    "df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN], format=\"%d-%b-%Y\")\n",
    "\n",
    "\n",
    "# Encoding categorical data into numerical:\n",
    "def encode(df: DataFrame, original_column: str, new_column: str):\n",
    "    df[new_column], _unique = pd.factorize(df[original_column])\n",
    "\n",
    "\n",
    "ORIGINAL_COLUMNS = [\"Time\", \"State\", \"Group\"]\n",
    "NEW_COLUMNS = [\"Numerical_Time\", \"Numerical_State\", \"Numerical_Group\"]\n",
    "\n",
    "for original_column, new_column in zip(ORIGINAL_COLUMNS, NEW_COLUMNS):\n",
    "    encode(df, original_column, new_column)\n",
    "\n",
    "\n",
    "# Binning Sales column to create Sales_Range:\n",
    "SALES_RANGE = \"Sales_Range\"\n",
    "\n",
    "min = df[SALES_COLUMN].min()\n",
    "q2 = df[SALES_COLUMN].quantile(0.5)\n",
    "max = df[SALES_COLUMN].max()\n",
    "\n",
    "bin_edges = [min, q1, q2, q3, max]\n",
    "bin_labels = [\"0-25%\", \"25%-50%\", \"50%-75%\", \"75%-100%\"]\n",
    "\n",
    "df[SALES_RANGE] = pd.cut(\n",
    "    df[SALES_COLUMN], bins=bin_edges, labels=bin_labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# Normalization\n",
    "cleaned_df = df.copy(deep=True)\n",
    "normalized_df = cleaned_df.copy(deep=True)\n",
    "new_numerical_columns = normalized_df.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "SCALER = MinMaxScaler()\n",
    "\n",
    "normalized_df[new_numerical_columns] = SCALER.fit_transform(\n",
    "    normalized_df[new_numerical_columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Saving**\n",
    "\n",
    "_It involves creating a new DataFrame with the wrangled data and save it into a new csv file._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv(\"./Data/AAL_Q4-2020_Sales_Cleaned.csv\", index=False)\n",
    "normalized_df.to_csv(\"./Data/AAL_Q4-2020_Sales_Cleaned_and_Normalized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Analysis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Descriptive Statistical Analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      7560.0\n",
      "mean      45014.0\n",
      "std       32254.0\n",
      "min        5000.0\n",
      "25%       20000.0\n",
      "50%       35000.0\n",
      "75%       65000.0\n",
      "max      162500.0\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cleaned_stats = cleaned_df['Sales'].describe().round()\n",
    "print(cleaned_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
