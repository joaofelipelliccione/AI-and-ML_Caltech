{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AAL Australia: 4Q Sales Report**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data Wrangling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 Data Inspection**\n",
    "\n",
    "_It's the process of getting familiar with the data in order to identify quality and structure issues._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./Data/AAL_Q4-2020_Sales.csv\")\n",
    "\n",
    "print(\"First 5 rows of the DataFrame:\")\n",
    "print(df.head(5))\n",
    "\n",
    "print(f\"\\nLast 5 rows of the DataFrame:\")\n",
    "print(df.tail(5))\n",
    "\n",
    "print(\"\\nDataFrame Summary\")\n",
    "print(df.info())\n",
    "\n",
    "has_null = df.isnull().values.any()\n",
    "print(\"\\nDoes the DataFrame have any null value?:\", has_null)\n",
    "\n",
    "number_of_duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicates: {number_of_duplicates}\")\n",
    "\n",
    "print(\"\\nList of numerical columns:\")\n",
    "numerical_columns = df.select_dtypes(include=[\"number\"]).columns\n",
    "print(numerical_columns)\n",
    "\n",
    "print(\"\\nList of categorical columns:\")\n",
    "categorical_columns = df.select_dtypes(exclude=[\"number\"]).columns\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Data Cleaning**\n",
    "\n",
    "_It's the process of handling missing data, removing duplicates, converting data types, trimming whitespace, correcting inconsistencies, standardizing formats, dealing with outliers, and validating accuracy._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling duplicates:\n",
    "if number_of_duplicates > 0:\n",
    "    df = df.drop_duplicates(keep=\"first\")\n",
    "\n",
    "# Handling missing data for numerical columns:\n",
    "for column in numerical_columns:\n",
    "    if df[column].isnull().any():\n",
    "        column_median = df[column].median()\n",
    "        df[column] = df[column].fillna(column_median)\n",
    "\n",
    "# Handling missing data for categorical columns:\n",
    "for column in categorical_columns:\n",
    "    if df[column].isnull().any():\n",
    "        df[column] = df[column].fillna(\"Unknown\")\n",
    "\n",
    "\n",
    "# Identify and correct misspelled words and unnecessary whitespace:\n",
    "for column in categorical_columns:\n",
    "    if column != \"Date\":\n",
    "        df[column] = df[column].str.strip()\n",
    "        unique_values = df[column].unique()\n",
    "        print(f\"{column} unique values: {unique_values}\")\n",
    "\n",
    "# Handling Outliers:\n",
    "SALES_COLUMN = \"Sales\"\n",
    "\n",
    "q1 = df[SALES_COLUMN].quantile(0.25)\n",
    "q3 = df[SALES_COLUMN].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Tagging all the 'sales outliers' with True or False\n",
    "condition = (df[SALES_COLUMN] >= lower_bound) & (df[SALES_COLUMN] <= upper_bound)\n",
    "df[\"Sales_Outlier\"] = ~condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3 Data Transformation**\n",
    "\n",
    "_It involves converting data from its original form into a format that is more suitable for analysis._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Transforming Date column to YYYY-MM-DD:\n",
    "DATE_COLUMN = \"Date\"\n",
    "df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN], format=\"%d-%b-%Y\")\n",
    "\n",
    "\n",
    "# Encoding categorical data into numerical:\n",
    "def encode(df: DataFrame, original_column: str, new_column: str):\n",
    "    df[new_column], _unique = pd.factorize(df[original_column])\n",
    "\n",
    "\n",
    "ORIGINAL_COLUMNS = [\"Time\", \"State\", \"Group\"]\n",
    "NEW_COLUMNS = [\"Numerical_Time\", \"Numerical_State\", \"Numerical_Group\"]\n",
    "\n",
    "for original_column, new_column in zip(ORIGINAL_COLUMNS, NEW_COLUMNS):\n",
    "    encode(df, original_column, new_column)\n",
    "\n",
    "\n",
    "# Binning Sales column to create Sales_Range:\n",
    "SALES_RANGE = \"Sales_Range\"\n",
    "\n",
    "min = df[SALES_COLUMN].min()\n",
    "q2 = df[SALES_COLUMN].quantile(0.5)\n",
    "max = df[SALES_COLUMN].max()\n",
    "\n",
    "bin_edges = [min, q1, q2, q3, max]\n",
    "bin_labels = [\"0-25%\", \"25%-50%\", \"50%-75%\", \"75%-100%\"]\n",
    "\n",
    "df[SALES_RANGE] = pd.cut(\n",
    "    df[SALES_COLUMN], bins=bin_edges, labels=bin_labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# Normalization\n",
    "cleaned_df = df.copy(deep=True)\n",
    "normalized_df = cleaned_df.copy(deep=True)\n",
    "new_numerical_columns = normalized_df.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "SCALER = MinMaxScaler()\n",
    "\n",
    "normalized_df[new_numerical_columns] = SCALER.fit_transform(\n",
    "    normalized_df[new_numerical_columns]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Saving**\n",
    "\n",
    "_It involves creating a new DataFrame with the wrangled data and save it into a new csv file._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_df.to_csv(\"./Data/AAL_Q4-2020_Sales_Cleaned.csv\", index=False)\n",
    "# normalized_df.to_csv(\"./Data/AAL_Q4-2020_Sales_Cleaned_and_Normalized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Analysis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Descriptive Statistical Analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_stats = cleaned_df[\"Sales\"].describe().round()\n",
    "print(cleaned_stats)\n",
    "\n",
    "\"\"\"\n",
    "The dataset of 7,560 sales records shows a broad range of sales amounts from $5,000 to $162,500, highlighting diverse\n",
    "transaction sizes.\n",
    "\n",
    "With an average sale of $45,014 but a high standard deviation of $32,254, the data reveals a wide spread of sales figures,\n",
    "indicating a mix of low, medium, and high transactions.\n",
    "\n",
    "The sales distribution is right-skewed, as shown by 25% of sales being $20,000 or below, the median at $35,000, and 75% of sales\n",
    "not exceeding $65,000, though some transactions reach up to $162,500, suggesting outlier or high-value sales.\n",
    "\n",
    "The insights point towards focusing strategies on enhancing the value of transactions in the lower quartiles, targeting\n",
    "medium-value transactions for growth, and learning from high-value sales to boost overall performance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Ranking Analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = cleaned_df.copy(deep=True)\n",
    "\n",
    "# Units:\n",
    "sales_by_unit = ranking_df.groupby(\"Unit\")[\"Sales\"].sum().reset_index()\n",
    "sorted_sales_by_unit = sales_by_unit.sort_values(\"Sales\", ascending=False)\n",
    "\n",
    "top_3_units = sorted_sales_by_unit.head(3)\n",
    "bottom_3_units = sorted_sales_by_unit.tail(3)\n",
    "\n",
    "print(\"\\nTop 3 STORES (Units) with the highest total sales:\")\n",
    "print(top_3_units)\n",
    "\n",
    "print(\"\\nBottom 3 STORES (Units) with the lowest total Sales:\")\n",
    "print(bottom_3_units.sort_values(\"Sales\", ascending=True))\n",
    "\n",
    "# State:\n",
    "sales_by_state = ranking_df.groupby(\"State\")[\"Sales\"].sum().reset_index()\n",
    "sorted_sales_by_state = sales_by_state.sort_values(\"Sales\", ascending=False)\n",
    "\n",
    "top_3_states = sorted_sales_by_state.head(3)\n",
    "bottom_3_states = sorted_sales_by_state.tail(3)\n",
    "\n",
    "print(\"\\nTop 3 STATES with the highest total sales:\")\n",
    "print(top_3_states)\n",
    "\n",
    "print(\"\\nBottom 3 STATES with the lowest total Sales:\")\n",
    "print(bottom_3_states.sort_values(\"Sales\", ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Pivot Table**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivot table 1: Total sales by State, Group, and Month\n",
      "Month                 10        11         12      Total\n",
      "State Group                                             \n",
      "NSW   Kids       6340000   5312500    6935000   18587500\n",
      "      Men        6270000   5490000    7262500   19022500\n",
      "      Seniors    5915000   5362500    6910000   18187500\n",
      "      Women      6482500   5325000    7365000   19172500\n",
      "NT    Kids       2140000   1332500    2227500    5700000\n",
      "      Men        2122500   1280000    2360000    5762500\n",
      "      Seniors    1970000   1260000    2235000    5465000\n",
      "      Women      1990000   1385000    2277500    5652500\n",
      "QLD   Kids       2837500   2042500    3630000    8510000\n",
      "      Men        2855000   1982500    3555000    8392500\n",
      "      Seniors    2772500   1992500    3425000    8190000\n",
      "      Women      2655000   2092500    3577500    8325000\n",
      "SA    Kids       4990000   3810000    5715000   14515000\n",
      "      Men        5087500   3910000    5657500   14655000\n",
      "      Seniors    5530000   3795000    5392500   14717500\n",
      "      Women      5002500   4017500    5950000   14970000\n",
      "TAS   Kids       2050000   1472500    2252500    5775000\n",
      "      Men        2035000   1350000    2372500    5757500\n",
      "      Seniors    2022500   1385000    2242500    5650000\n",
      "      Women      1907500   1337500    2332500    5577500\n",
      "VIC   Kids       8312500   7542500   10505000   26360000\n",
      "      Men        8387500   7270000   10750000   26407500\n",
      "      Seniors    8367500   7232500   10715000   26315000\n",
      "      Women      8375000   7485000   10622500   26482500\n",
      "WA    Kids       1965000   1370000    2290000    5625000\n",
      "      Men        2127500   1332500    2292500    5752500\n",
      "      Seniors    1987500   1295000    2230000    5512500\n",
      "      Women      1792500   1220000    2250000    5262500\n",
      "Total          114290000  90682500  135330000  340302500\n",
      "\n",
      "Pivot table 2: Average sales by State, Group, and Month\n",
      "Month                  10        11         12   Average\n",
      "State   Group                                           \n",
      "NSW     Kids     70444.44  59027.78   77055.56  68842.59\n",
      "        Men      69666.67  61000.00   80694.44  70453.70\n",
      "        Seniors  65722.22  59583.33   76777.78  67361.11\n",
      "        Women    72027.78  59166.67   81833.33  71009.26\n",
      "NT      Kids     23777.78  14805.56   24750.00  21111.11\n",
      "        Men      23583.33  14222.22   26222.22  21342.59\n",
      "        Seniors  21888.89  14000.00   24833.33  20240.74\n",
      "        Women    22111.11  15388.89   25305.56  20935.19\n",
      "QLD     Kids     31527.78  22694.44   40333.33  31518.52\n",
      "        Men      31722.22  22027.78   39500.00  31083.33\n",
      "        Seniors  30805.56  22138.89   38055.56  30333.33\n",
      "        Women    29500.00  23250.00   39750.00  30833.33\n",
      "SA      Kids     55444.44  42333.33   63500.00  53759.26\n",
      "        Men      56527.78  43444.44   62861.11  54277.78\n",
      "        Seniors  61444.44  42166.67   59916.67  54509.26\n",
      "        Women    55583.33  44638.89   66111.11  55444.44\n",
      "TAS     Kids     22777.78  16361.11   25027.78  21388.89\n",
      "        Men      22611.11  15000.00   26361.11  21324.07\n",
      "        Seniors  22472.22  15388.89   24916.67  20925.93\n",
      "        Women    21194.44  14861.11   25916.67  20657.41\n",
      "VIC     Kids     92361.11  83805.56  116722.22  97629.63\n",
      "        Men      93194.44  80777.78  119444.44  97805.56\n",
      "        Seniors  92972.22  80361.11  119055.56  97462.96\n",
      "        Women    93055.56  83166.67  118027.78  98083.33\n",
      "WA      Kids     21833.33  15222.22   25444.44  20833.33\n",
      "        Men      23638.89  14805.56   25472.22  21305.56\n",
      "        Seniors  22083.33  14388.89   24777.78  20416.67\n",
      "        Women    19916.67  13555.56   25000.00  19490.74\n",
      "Average          45353.17  35985.12   53702.38  45013.56\n"
     ]
    }
   ],
   "source": [
    "pivot_df = cleaned_df.copy(deep=True)\n",
    "\n",
    "pivot_df[\"Year\"] = pivot_df[\"Date\"].dt.year\n",
    "pivot_df[\"Month\"] = pivot_df[\"Date\"].dt.month\n",
    "\n",
    "pivot_table_1 = pd.pivot_table(\n",
    "    pivot_df,\n",
    "    values=\"Sales\",\n",
    "    index=[\"State\", \"Group\"],\n",
    "    columns=[\"Month\"],\n",
    "    aggfunc=\"sum\",\n",
    "    margins=True,\n",
    "    margins_name=\"Total\",\n",
    ")\n",
    "\n",
    "print(\"\\nPivot table 1: Total sales by State, Group, and Month\")\n",
    "print(pivot_table_1)\n",
    "\n",
    "pivot_table_2 = pd.pivot_table(\n",
    "    pivot_df,\n",
    "    values=\"Sales\",\n",
    "    index=[\"State\", \"Group\"],\n",
    "    columns=[\"Month\"],\n",
    "    aggfunc=\"mean\",\n",
    "    margins=True,\n",
    "    margins_name=\"Average\",\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nPivot table 2: Average sales by State, Group, and Month\")\n",
    "print(pivot_table_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
